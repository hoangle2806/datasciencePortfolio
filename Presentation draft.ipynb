{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Natural Language Processing:<br> the Old and the New</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation \n",
    "1. Worked with Siri<br><br>\n",
    "2. Interested in cool machine learning application<br><br>\n",
    "<br><br><br><br><br><br><br>\n",
    "<br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick explanation on machine learning\n",
    "x = 2 ; y = 4 <br>\n",
    "x = 4 ; y = 8 <br>\n",
    "x = 5 ; y = 10 <br>\n",
    "x = 1 ; y = ? <br>\n",
    "<br><br><br><br><br><br><br>\n",
    "y = 2x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasons for the raise of machine learning\n",
    "1. Cheap + fast memory and CPU<br><br>\n",
    "2. Cloud computing available with reasonable price<br><br>\n",
    "<br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP with Yelp's data\n",
    "1. Collect data <br><br>\n",
    "2. Clean data (normalization, transformation, and vectorization)<br><br>\n",
    "3. Choose predictive model<br><br>\n",
    "4. Metrics <br>\n",
    "<br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of this project is to extract data from json format and export in pandas dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_directory = 'yelp_dataset_challenge_round9'\n",
    "review_only_filepath = os.path.join(data_directory,\n",
    "                                    'yelp_academic_dataset_review.json')\n",
    "\n",
    "businesses_filepath = os.path.join(data_directory, 'yelp_academic_dataset_business.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48485  total restaurants in the dataset.\n"
     ]
    }
   ],
   "source": [
    "restaurant_id = set()\n",
    "\n",
    "with open(businesses_filepath) as f:\n",
    "    for line in f:\n",
    "        business = json.loads(line)\n",
    "        #there's case the business is None\n",
    "        if business['categories'] is not None and 'Restaurants' in business['categories']:\n",
    "            restaurant_id.add(business['business_id'])\n",
    "            \n",
    "\n",
    "print '{}'.format(len(restaurant_id)), \" total restaurants in the dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting into the habits that export file every modification make alonng the way\n",
    "intermediate_directory = 'intermediate'\n",
    "restaurant_review_text_filepath = os.path.join(intermediate_directory,'restaurant_review_name.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done grouping text\n",
      "CPU times: user 1min 48s, sys: 4.46 s, total: 1min 52s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if True:\n",
    "    with codecs.open(restaurant_review_text_filepath,'w', encoding = 'utf_8') as res_review:\n",
    "        with codecs.open(review_only_filepath,encoding = 'utf_8') as review_only_file:\n",
    "            for line in review_only_file:\n",
    "                review = json.loads(line)\n",
    "                if review['business_id'] not in restaurant_id:\n",
    "                    continue\n",
    "                text = review['text'].encode('utf-8')\n",
    "                res_review.write(str(review['business_id'])+ '\\t' +review['text'].replace('\\n', '\\\\n')+ \n",
    "                                 '\\t'+ str(review['stars']) + '\\n')\n",
    "    print \"Done grouping text\"\n",
    "else: \n",
    "    with open(restaurant_review_text_filepath) as review_txt_file:\n",
    "        #means that there's a file already existed. \n",
    "        pass\n",
    "        \n",
    "    print \"Already created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4P-vTvE6cncJyUyLh73pxw</td>\n",
       "      <td>This place is a area staple! Been around for y...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4P-vTvE6cncJyUyLh73pxw</td>\n",
       "      <td>Got my mojo back after having a few of their a...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4P-vTvE6cncJyUyLh73pxw</td>\n",
       "      <td>Don't go here for the decor, but the staff is ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4P-vTvE6cncJyUyLh73pxw</td>\n",
       "      <td>I believe in awarding stars bearing in mind th...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4P-vTvE6cncJyUyLh73pxw</td>\n",
       "      <td>If you like fried food and laid back, then thi...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business                                            reviews  \\\n",
       "0  4P-vTvE6cncJyUyLh73pxw  This place is a area staple! Been around for y...   \n",
       "1  4P-vTvE6cncJyUyLh73pxw  Got my mojo back after having a few of their a...   \n",
       "2  4P-vTvE6cncJyUyLh73pxw  Don't go here for the decor, but the staff is ...   \n",
       "3  4P-vTvE6cncJyUyLh73pxw  I believe in awarding stars bearing in mind th...   \n",
       "4  4P-vTvE6cncJyUyLh73pxw  If you like fried food and laid back, then thi...   \n",
       "\n",
       "   rating  \n",
       "0     4.0  \n",
       "1     4.0  \n",
       "2     4.0  \n",
       "3     5.0  \n",
       "4     4.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(restaurant_review_text_filepath, sep = '\\t',names = ['business', 'reviews', 'rating'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of row in data frame 2578790\n"
     ]
    }
   ],
   "source": [
    "print \"Number of row in data frame {}\".format(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there're 2 million rows in the data set. It's too big for my computer, so I only used 10% of data to demonstrate the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2287541</th>\n",
       "      <td>Gaq3S9lmjXVcuDCZ8ulppw</td>\n",
       "      <td>I wasn't really impressed with this sushi join...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087268</th>\n",
       "      <td>ZX9eujPNUxqWEWYdr4Ulqg</td>\n",
       "      <td>Wow! What a treat. Started off with a cup of t...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369363</th>\n",
       "      <td>SZEFE5hL7aN5nM-A44iPwQ</td>\n",
       "      <td>Gorgeous and romantic interiors.  Spectacular ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545381</th>\n",
       "      <td>7KkgMcbVaetryW1wwpzvvA</td>\n",
       "      <td>I  had the Tuesday special - coconut shrimp ta...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112117</th>\n",
       "      <td>Xra1TtWtf069Am5hHWs3Ug</td>\n",
       "      <td>Seriously good Italian food! Though the dining...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       business  \\\n",
       "2287541  Gaq3S9lmjXVcuDCZ8ulppw   \n",
       "2087268  ZX9eujPNUxqWEWYdr4Ulqg   \n",
       "1369363  SZEFE5hL7aN5nM-A44iPwQ   \n",
       "1545381  7KkgMcbVaetryW1wwpzvvA   \n",
       "1112117  Xra1TtWtf069Am5hHWs3Ug   \n",
       "\n",
       "                                                   reviews  rating  \n",
       "2287541  I wasn't really impressed with this sushi join...     3.0  \n",
       "2087268  Wow! What a treat. Started off with a cup of t...     5.0  \n",
       "1369363  Gorgeous and romantic interiors.  Spectacular ...     5.0  \n",
       "1545381  I  had the Tuesday special - coconut shrimp ta...     3.0  \n",
       "1112117  Seriously good Italian food! Though the dining...     5.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#while sampling the data set, it also randomized the dataframe. \n",
    "temp = df.sample(frac = 0.1)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#export subset of the data\n",
    "if True:\n",
    "    export_subset = os.path.join(intermediate_directory,'restaurant_review_name_subset.txt')\n",
    "else:\n",
    "    temp.to_csv(export_subset, header= ['business', 'reviews', 'rating'], index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This will end script #1, create another script to load the data and start processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaq3S9lmjXVcuDCZ8ulppw</td>\n",
       "      <td>I wasn't really impressed with this sushi join...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZX9eujPNUxqWEWYdr4Ulqg</td>\n",
       "      <td>Wow! What a treat. Started off with a cup of t...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SZEFE5hL7aN5nM-A44iPwQ</td>\n",
       "      <td>Gorgeous and romantic interiors.  Spectacular ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7KkgMcbVaetryW1wwpzvvA</td>\n",
       "      <td>I  had the Tuesday special - coconut shrimp ta...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xra1TtWtf069Am5hHWs3Ug</td>\n",
       "      <td>Seriously good Italian food! Though the dining...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business                                            reviews  \\\n",
       "0  Gaq3S9lmjXVcuDCZ8ulppw  I wasn't really impressed with this sushi join...   \n",
       "1  ZX9eujPNUxqWEWYdr4Ulqg  Wow! What a treat. Started off with a cup of t...   \n",
       "2  SZEFE5hL7aN5nM-A44iPwQ  Gorgeous and romantic interiors.  Spectacular ...   \n",
       "3  7KkgMcbVaetryW1wwpzvvA  I  had the Tuesday special - coconut shrimp ta...   \n",
       "4  Xra1TtWtf069Am5hHWs3Ug  Seriously good Italian food! Though the dining...   \n",
       "\n",
       "   rating  \n",
       "0     3.0  \n",
       "1     5.0  \n",
       "2     5.0  \n",
       "3     3.0  \n",
       "4     5.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(export_subset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because reviews will have numbers, articles, emoji, and punctuation which have no value for the task, so we remove it and lowercase for all of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#created a bigger stopwords library. \n",
    "stop.extend(['may','also','zero','one','two','three','four','five','six','seven','eight',\n",
    "             'nine','ten','across','among','beside','however','yet','within']+list(ascii_lowercase))\n",
    "stop = set(sorted(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    '''this function will remove all punctuations and numbers'''\n",
    "    #import regular expression library to do string manipulations\n",
    "    import re\n",
    "    temp = str(x)\n",
    "    temp = re.sub('[!\"#%\\'()*+,-./:;<=>?@\\[\\]^_`{|}~1234567890’”“′‘\\\\\\]',' ',temp)\n",
    "    temp = temp.lower().split(\" \")\n",
    "    return ' '.join([ i for i in temp if i not in stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleaned_text_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaq3S9lmjXVcuDCZ8ulppw</td>\n",
       "      <td>I wasn't really impressed with this sushi join...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>really impressed sushi joint  typical ayce for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZX9eujPNUxqWEWYdr4Ulqg</td>\n",
       "      <td>Wow! What a treat. Started off with a cup of t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wow  treat  started cup best coffee ever  ask ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SZEFE5hL7aN5nM-A44iPwQ</td>\n",
       "      <td>Gorgeous and romantic interiors.  Spectacular ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gorgeous romantic interiors   spectacular food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7KkgMcbVaetryW1wwpzvvA</td>\n",
       "      <td>I  had the Tuesday special - coconut shrimp ta...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tuesday special   coconut shrimp tacos rice b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xra1TtWtf069Am5hHWs3Ug</td>\n",
       "      <td>Seriously good Italian food! Though the dining...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>seriously good italian food  though dining roo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business                                            reviews  \\\n",
       "0  Gaq3S9lmjXVcuDCZ8ulppw  I wasn't really impressed with this sushi join...   \n",
       "1  ZX9eujPNUxqWEWYdr4Ulqg  Wow! What a treat. Started off with a cup of t...   \n",
       "2  SZEFE5hL7aN5nM-A44iPwQ  Gorgeous and romantic interiors.  Spectacular ...   \n",
       "3  7KkgMcbVaetryW1wwpzvvA  I  had the Tuesday special - coconut shrimp ta...   \n",
       "4  Xra1TtWtf069Am5hHWs3Ug  Seriously good Italian food! Though the dining...   \n",
       "\n",
       "   rating                                  cleaned_text_data  \n",
       "0     3.0  really impressed sushi joint  typical ayce for...  \n",
       "1     5.0  wow  treat  started cup best coffee ever  ask ...  \n",
       "2     5.0  gorgeous romantic interiors   spectacular food...  \n",
       "3     3.0   tuesday special   coconut shrimp tacos rice b...  \n",
       "4     5.0  seriously good italian food  though dining roo...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create another colummn for cleaned text\n",
    "df['cleaned_text_data'] = df['reviews'].apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleaned_text_data</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaq3S9lmjXVcuDCZ8ulppw</td>\n",
       "      <td>I wasn't really impressed with this sushi join...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>really impressed sushi joint  typical ayce for...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZX9eujPNUxqWEWYdr4Ulqg</td>\n",
       "      <td>Wow! What a treat. Started off with a cup of t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wow  treat  started cup best coffee ever  ask ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SZEFE5hL7aN5nM-A44iPwQ</td>\n",
       "      <td>Gorgeous and romantic interiors.  Spectacular ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gorgeous romantic interiors   spectacular food...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7KkgMcbVaetryW1wwpzvvA</td>\n",
       "      <td>I  had the Tuesday special - coconut shrimp ta...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tuesday special   coconut shrimp tacos rice b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xra1TtWtf069Am5hHWs3Ug</td>\n",
       "      <td>Seriously good Italian food! Though the dining...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>seriously good italian food  though dining roo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business                                            reviews  \\\n",
       "0  Gaq3S9lmjXVcuDCZ8ulppw  I wasn't really impressed with this sushi join...   \n",
       "1  ZX9eujPNUxqWEWYdr4Ulqg  Wow! What a treat. Started off with a cup of t...   \n",
       "2  SZEFE5hL7aN5nM-A44iPwQ  Gorgeous and romantic interiors.  Spectacular ...   \n",
       "3  7KkgMcbVaetryW1wwpzvvA  I  had the Tuesday special - coconut shrimp ta...   \n",
       "4  Xra1TtWtf069Am5hHWs3Ug  Seriously good Italian food! Though the dining...   \n",
       "\n",
       "   rating                                  cleaned_text_data sentiment  \n",
       "0     3.0  really impressed sushi joint  typical ayce for...  negative  \n",
       "1     5.0  wow  treat  started cup best coffee ever  ask ...  positive  \n",
       "2     5.0  gorgeous romantic interiors   spectacular food...  positive  \n",
       "3     3.0   tuesday special   coconut shrimp tacos rice b...  negative  \n",
       "4     5.0  seriously good italian food  though dining roo...  positive  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert rating into a number\n",
    "df['rating'] = df['rating'].apply(lambda x: float(x))\n",
    "\n",
    "#sentiment for each review\n",
    "df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x >3 else 'negative')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking numbers of positive and negative in dataframe\n",
      "           business  reviews  rating  cleaned_text_data\n",
      "sentiment                                              \n",
      "negative      90589    90463   90403              90589\n",
      "positive      90589    90589   90589              90589\n"
     ]
    }
   ],
   "source": [
    "#seperate positive and negative \n",
    "positive_text = df[df['sentiment'] ==  'positive']\n",
    "negative_text = df[df['sentiment'] ==  'negative']\n",
    "\n",
    "#keep positive : negative ration to be 1:1\n",
    "pos_negative_ratio = len(negative_text)/float(len(positive_text))\n",
    "temp = positive_text.sample(frac = pos_negative_ratio)\n",
    "small_df = pd.concat([negative_text,temp])\n",
    "\n",
    "#re-randomize data after concatenation. \n",
    "for _ in range(100):\n",
    "    small_df = small_df.sample(frac = 1)\n",
    "print \"Checking numbers of positive and negative in dataframe\"\n",
    "print small_df.groupby('sentiment').count()\n",
    "\n",
    "#split data into test set and train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(small_df['cleaned_text_data'],small_df['sentiment'], test_size =0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose machine learning model: bag of words and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bag of words representation\n",
    "3 setences\n",
    "\n",
    "I love food <br>\n",
    "Food was awful <br>\n",
    "I love service <br>\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td>Words</td>\n",
    "    <th>I</th>\n",
    "    <th>love</th> \n",
    "    <th>food</th>\n",
    "    <th>was</th>\n",
    "    <th>awful</th>\n",
    "    <th>service</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Count</td>\n",
    "    <td>2</td>\n",
    "    <td>2</td> \n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>awful food</td>\n",
    "    <td>0</td>\n",
    "    <td>0</td> \n",
    "    <td>1</td>\n",
    "    <td>0</td>\n",
    "    <td>1</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model\n",
    "<img src = 'regression.png'></img>\n",
    "<img src='sigmoid.png'> </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.87      0.85      0.86     27158\n",
      "   positive       0.85      0.87      0.86     27196\n",
      "\n",
      "avg / total       0.86      0.86      0.86     54354\n",
      "\n",
      "CPU times: user 2min 21s, sys: 2.67 s, total: 2min 24s\n",
      "Wall time: 44.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_clf = Pipeline([('vect', CountVectorizer(decode_error = 'ignore')),\n",
    "                     ('clf', LogisticRegression(n_jobs = 7))\n",
    "                    ])\n",
    "text_clf.fit(x_train,y_train)\n",
    "predicted = text_clf.predict(x_test)\n",
    "\n",
    "print metrics.classification_report(y_test,predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new way: word2vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: <br>\n",
    "We withdraw money from the bank. It is where we keep our money <br>\n",
    "<br>\n",
    "We withdraw money from the ______. It is where we keep our money\n",
    "<br>\n",
    "<br>\n",
    "The word \"bank\" will be represented by the word surrounding it. <br>\n",
    "bank = [ 0.22 -0.13 ...] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prep text for Word2Vec model\n",
    "\n",
    "sentences = [i.split() for i in x_train.values]\n",
    "dimsize = 100\n",
    "if True:\n",
    "    model = Word2Vec(sentences, size=dimsize, window=5, min_count = 10, workers=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.8376318216323853),\n",
       " ('great', 0.7993384599685669),\n",
       " ('okay', 0.734479546546936),\n",
       " ('tasty', 0.7247240543365479),\n",
       " ('alright', 0.7047333717346191),\n",
       " ('awesome', 0.6951277256011963),\n",
       " ('ok', 0.6799435615539551),\n",
       " ('amazing', 0.676638126373291),\n",
       " ('bad', 0.6674460172653198),\n",
       " ('excellent', 0.6643167734146118)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.83798039,  3.10056496,  1.15078843, -0.77607244, -0.28369644,\n",
       "        1.0438925 ,  1.64269817, -0.35212097,  0.9733761 ,  1.30047345,\n",
       "       -0.51472402,  0.796911  ,  0.33340213, -0.32971922,  0.44877133,\n",
       "       -0.1049996 ,  2.35728383,  0.18197046, -1.06702483,  0.62371641,\n",
       "        3.65429425, -0.94448858,  1.8061595 , -0.08583735,  0.95774978,\n",
       "        1.31160033,  1.29080546, -1.27874053, -1.73168182, -1.06874454,\n",
       "        1.06354654, -0.74416751, -0.59946012,  1.01054847, -0.71201831,\n",
       "        2.58485126,  2.05472398,  0.17161466, -1.57106102, -0.09422354,\n",
       "        1.30297554, -0.29776838,  2.17285848, -1.41310346,  0.1578698 ,\n",
       "        0.64610398,  0.8094359 ,  0.93437093, -0.2296167 , -0.62909347,\n",
       "       -0.63703704,  1.74894023, -1.7058562 , -0.87453276,  0.47888848,\n",
       "       -0.76825511,  0.73481482, -0.64561987,  1.02129984,  1.60558689,\n",
       "       -1.44627929,  0.85575485, -0.6373418 , -2.02705669,  1.71181154,\n",
       "       -0.00501073,  0.25694141,  0.05391138,  1.33624947,  0.98411703,\n",
       "        1.42121589, -1.96938682,  1.05950665, -0.54860771,  2.24024224,\n",
       "       -1.19525754,  0.69903779, -0.35931161,  0.78210753, -1.89843702,\n",
       "       -0.32958144,  1.85253417,  0.19459616, -1.0391866 , -1.20856702,\n",
       "        0.42619914, -1.00662601, -0.31279105, -0.81037152,  0.86800206,\n",
       "        0.28296214,  0.20227295,  1.82258773,  1.18002963,  2.60830617,\n",
       "       -0.74098623,  0.33119619,  0.9879601 ,  1.51961339, -2.47466683], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_word_vectors(wordlist,size):\n",
    "    sumvec=np.zeros(shape=(1,size))\n",
    "    wordcnt=0\n",
    "    wordlist = wordlist.split()\n",
    "    for w in wordlist:\n",
    "        if w in model:\n",
    "            sumvec += model[w]\n",
    "            wordcnt +=1\n",
    "    \n",
    "    if wordcnt ==0:\n",
    "        return sumvec\n",
    "    \n",
    "    else:\n",
    "        return sumvec / wordcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create average vector for train and test from model\n",
    "#returned list of numpy arrays are then stacked \n",
    "X_train=np.concatenate([avg_word_vectors(w,dimsize) for w in x_train.values])\n",
    "X_test=np.concatenate([avg_word_vectors(w,dimsize) for w in x_test.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.84      0.85      0.85     27258\n",
      "   positive       0.85      0.84      0.85     27096\n",
      "\n",
      "avg / total       0.85      0.85      0.85     54354\n",
      "\n",
      "CPU times: user 5.12 s, sys: 56 ms, total: 5.18 s\n",
      "Wall time: 4.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_clf = LogisticRegression(n_jobs = 7)\n",
    "text_clf = text_clf.fit(X_train,y_train)\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print metrics.classification_report(y_test,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "always go lunch  food fresh yummy  every wrap lunch bowl comes side pasta chips salsa   nparking sucks  try go peak lunch time  usually go early late lunch \n",
      "prediction: positive\n"
     ]
    }
   ],
   "source": [
    "print x_test.values[0]\n",
    "print \"prediction: {}\".format(predicted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The both model only achieve 80% for F1-score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Take home message:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The old and the new has their advantage/disadvantage <br><br>\n",
    "2. sentiment analyis is a foundation for real application such as fake reviews dection<br><br>\n",
    "3. Promising future for NLP<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
